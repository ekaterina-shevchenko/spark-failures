version: "3"

services:

  spark-master:
    image: "datamechanics/spark:jvm-only-3.2-latest"
    ports:
      - "8080:8080"
    environment:
      - CORES=1
      - MEMORY=3G
    deploy:
      placement:
        # set node labels using docker node update --label-add key=value <NODE ID> from swarm manager
        constraints:
          - node.labels.role==worker
    networks:
      - spark-network

  spark-worker:
    image: "datamechanics/spark:jvm-only-3.2-latest"
    ports:
      - "8081:8081"
    environment:
      - CORES=1
      - MEMORY=3G
    deploy:
      placement:
        constraints:
          - node.labels.role==worker
      replicas: 3
    networks:
      - spark-network

  driver:
    image: "maven:3.8.4-openjdk-11"
    ports:
      - "8090:8080"
    deploy:
      placement:
        constraints:
          - node.labels.role==master
    networks:
      - spark-network

  generator:
    image: "maven:3.8.4-openjdk-11"
    ports:
      - "8091:8080"
    deploy:
      placement:
        constraints:
          - node.labels.role==master
    networks:
      - spark-network

  kafka:
    image: "wurstmeister/kafka:latest"
    ports:
      - "8082:8081"
    environment:
      - KAFKA_ZOOKEEPER_CONNECT=localhost:2181
    deploy:
      placement:
        constraints:
          - node.labels.role==master
    networks:
      - spark-network

  zookeeper:
    image: "zookeeper:latest" # This image is configured with volumes at /data and /datalog to hold the Zookeeper in-memory database snapshots and the transaction log of updates to the database
    ports:
      - "2181:2181"
    restart: always # Since the Zookeeper "fails fast" it's better to always restart it
    environment:
      - ZOO_LOG4J_PROP="INFO,ROLLINGFILE" # Redirects logging to /logs/zookeeper.log, the image already has a volume in /logs
    deploy:
      placement:
        constraints:
          - node.labels.role==master
    networks:
      - spark-network

networks:
  spark-network:
    driver: overlay