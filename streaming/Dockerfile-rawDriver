#
# Build stage
#
FROM maven:3.8.4-openjdk-11-slim AS build

COPY common /home/app/common
COPY generator /home/app/generator
COPY streaming /home/app/streaming
COPY structured-streaming /home/app/structured-streaming
COPY pom.xml /home/app/

# it's required for child modules to be able to find siblings modules in local maven repository
RUN cd /home/app/ && mvn clean install && cd /
RUN mvn -f /home/app/streaming/pom.xml clean package

#
# Package stage & spark download
#
FROM openjdk:11-jre-slim

ENV BASE_URL=https://archive.apache.org/dist/spark/
ENV SPARK_VERSION=3.2.0
ENV SCALA_VERSION=2.12.3
ENV HADOOP_VERSION=3.2
ENV SCALA_VERSION=2.13
If this env variable is not set, driver's classes will not be found
ENV SPARK_HOME=./spark

COPY --from=build /home/app/streaming/target/streaming-fat-1.0.jar /usr/local/lib/streaming.jar

RUN  apt-get update \
  && apt-get install -y wget \
  && rm -rf /var/lib/apt/lists/*

RUN wget ${BASE_URL}/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}-scala${SCALA_VERSION}.tgz \
      && tar -xvzf spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}-scala${SCALA_VERSION}.tgz \
      && mv spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}-scala${SCALA_VERSION} spark \
      && rm spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}-scala${SCALA_VERSION}.tgz \
      && cd /

ENTRYPOINT ["/opt/bitnami/spark/bin/spark-submit", "--master=spark://spark-master:7077", \
            "--deploy-mode=client", "--driver-memory=3g", \
            "--executor-memory=3g", "--executor-cores=2", \
            "--conf", "spark.jars.ivy=/tmp/.ivy", \
            "--class=de.tum.spark.failures.streaming.Application", "/usr/local/lib/streaming.jar"]